#!/usr/bin/env zsh

set -e -u -o pipefail  # Exit on error, undefined vars, pipe failures

# Default values
DEFAULT_REGION="fra1"
DEFAULT_TAG="14.3"
DEFAULT_VERSION="14.3-RELEASE"
DEFAULT_ARCH="amd64"

# Parse command line arguments using zparseopts
zparseopts -D -E -F -- \
    r:=region_arg -region:=region_arg \
    t:=tag_arg -tag:=tag_arg \
    v:=version_arg -version:=version_arg \
    a:=arch_arg -arch:=arch_arg \
    k:=token_arg -token:=token_arg \
    s=snapshot_arg -snapshot=snapshot_arg \
    h=help_arg -help=help_arg || exit 1

# Show help if requested
if [[ -n "${help_arg}" ]]; then
    cat >&2 <<EOF
Usage: ${0:t} [options]

Options:
    -r, --region REGION     DigitalOcean region (default: ${DEFAULT_REGION})
    -t, --tag TAG           FreeBSD tag (default: auto-derived from version)
    -v, --version VERSION   FreeBSD version (default: ${DEFAULT_VERSION})
    -a, --arch ARCH         Architecture (default: ${DEFAULT_ARCH})
    -k, --token TOKEN       DigitalOcean API token (overrides DIGITALOCEAN_ACCESS_TOKEN)
    -s, --snapshot          Use snapshot builds instead of releases
    -h, --help              Show this help message

Environment variables required:
    DIGITALOCEAN_ACCESS_TOKEN   DigitalOcean API token (or use -k/--token)
    STORAGE_BUCKET              Google Cloud Storage bucket (e.g., gs:bucket/path)
    STORAGE_URL                 Public URL for storage (e.g., https://storage.googleapis.com/bucket/path)

Examples:
    # Release build (tag auto-derived as "14.3")
    DIGITALOCEAN_ACCESS_TOKEN=token \\
    STORAGE_BUCKET=gs:mybucket/FreeBSD/image \\
    STORAGE_URL=https://mybucket.storage.googleapis.com/FreeBSD/image \\
    ${0:t} --region nyc3 --version 14.3-RELEASE

    # Snapshot build (tag auto-derived as "15.0")
    DIGITALOCEAN_ACCESS_TOKEN=token \\
    STORAGE_BUCKET=gs:mybucket/FreeBSD/image \\
    STORAGE_URL=https://mybucket.storage.googleapis.com/FreeBSD/image \\
    ${0:t} --region nyc3 --version 15.0-CURRENT --snapshot

    # Custom tag override
    DIGITALOCEAN_ACCESS_TOKEN=token \\
    STORAGE_BUCKET=gs:mybucket/FreeBSD/image \\
    STORAGE_URL=https://mybucket.storage.googleapis.com/FreeBSD/image \\
    ${0:t} --region nyc3 --version 14.3-RELEASE --tag custom-14.3
EOF
    exit 0
fi

# Define common variables with defaults
REGION="${region_arg[2]:-${DEFAULT_REGION}}"
DISTRIBUTION="Unknown"
VERSION="${version_arg[2]:-${DEFAULT_VERSION}}"
ARCH="${arch_arg[2]:-${DEFAULT_ARCH}}"
SNAPSHOT="${snapshot_arg[1]:+true}"
WORK_DIR="/tmp/freebsd-images"

# Derive TAG from VERSION if not explicitly provided
if [[ -n "${tag_arg[2]:-}" ]]; then
    TAG="${tag_arg[2]}"
else
    # Extract version number from VERSION (e.g., "14.2-RELEASE" -> "14.2", "15.0-CURRENT" -> "15.0")
    TAG="${VERSION%%-*}"
fi

# Set DigitalOcean token from command line or environment
if [[ -n "${token_arg[2]:-}" ]]; then
    DIGITALOCEAN_ACCESS_TOKEN="${token_arg[2]}"
fi

# Check for required environment variables
if [[ -z "${DIGITALOCEAN_ACCESS_TOKEN:-}" ]]; then
    echo "Error: DIGITALOCEAN_ACCESS_TOKEN environment variable is not set (use -k/--token or set the environment variable)" >&2
    exit 1
fi

if [[ -z "${STORAGE_BUCKET:-}" ]]; then
    echo "Error: STORAGE_BUCKET environment variable is not set" >&2
    exit 1
fi

if [[ -z "${STORAGE_URL:-}" ]]; then
    echo "Error: STORAGE_URL environment variable is not set" >&2
    exit 1
fi

# Define image types
image_types=("ufs" "zfs")

# Function to process and upload image
process_image() {
    local image_type="$1"

    # Determine base URL based on snapshot flag
    local base_url
    if [[ "${SNAPSHOT}" == "true" ]]; then
        base_url="https://download.freebsd.org/ftp/snapshots/VM-IMAGES/${VERSION}/${ARCH}/Latest"
    else
        base_url="https://download.freebsd.org/ftp/releases/VM-IMAGES/${VERSION}/${ARCH}/Latest"
    fi

    local filename="FreeBSD-${TAG}-${ARCH}-${image_type}.qcow2"
    local compressed_filename="${filename}.xz"
    local bz2_filename="${filename}.bz2"

    echo "Processing ${image_type} image..." >&2

    # Check if file already exists in storage
    if rclone lsf "${STORAGE_BUCKET}/${bz2_filename}" >/dev/null 2>&1; then
        echo "File ${bz2_filename} already exists in storage, skipping download and upload..." >&2
        echo "${STORAGE_URL}/${bz2_filename}"
        return 0
    fi

    # Create work directory
    mkdir -p "${WORK_DIR}"
    cd "${WORK_DIR}"

    # Download image if not exists - try both filename patterns
    if [[ ! -f "${compressed_filename}" ]]; then
        # Try dot pattern first: FreeBSD-VERSION-ARCH-BASIC-CLOUDINIT.TYPE.qcow2.xz
        local remote_filename_dot="FreeBSD-${VERSION}-${ARCH}-BASIC-CLOUDINIT.${image_type}.qcow2"
        local compressed_remote_filename_dot="${remote_filename_dot}.xz"

        echo "Downloading ${compressed_remote_filename_dot}..." >&2
        if curl -L -f -o "${compressed_filename}" "${base_url}/${compressed_remote_filename_dot}" 2>/dev/null; then
            echo "Downloaded using dot pattern." >&2
        else
            # Fallback to hyphen pattern: FreeBSD-VERSION-ARCH-BASIC-CLOUDINIT-TYPE.qcow2.xz
            local remote_filename_hyphen="FreeBSD-${VERSION}-${ARCH}-BASIC-CLOUDINIT-${image_type}.qcow2"
            local compressed_remote_filename_hyphen="${remote_filename_hyphen}.xz"

            echo "Dot pattern failed, trying hyphen pattern: ${compressed_remote_filename_hyphen}..." >&2
            if ! curl -L -o "${compressed_filename}" "${base_url}/${compressed_remote_filename_hyphen}"; then
                rm -f "${compressed_filename}"
                echo "Download failed, partial file removed" >&2
                exit 1
            fi
        fi
    fi

    # Decompress if needed
    if [[ ! -f "${decompressed_filename}" ]]; then
        echo "Decompressing ${compressed_filename}..." >&2
        if ! xz -d -k "${compressed_filename}"; then
            echo "Decompression failed. Examining file..." >&2
            echo "File type: $(file "${compressed_filename}")" >&2
            echo "File size: $(ls -lh "${compressed_filename}" | awk '{print $5}')" >&2
            echo "First 100 bytes:" >&2
            head -c 100 "${compressed_filename}" | xxd >&2
            rm -f "${compressed_filename}" "${decompressed_filename}"
            echo "Decompression failed, corrupted file removed. Please run again to re-download." >&2
            exit 1
        fi
    fi

    # Rename to desired filename if different
    if [[ "${decompressed_filename}" != "${filename}" && ! -f "${filename}" ]]; then
        mv "${decompressed_filename}" "${filename}"
    fi

    # Recompress with bzip2 if needed
    if [[ ! -f "${bz2_filename}" ]]; then
        echo "Compressing with bzip2..." >&2
        bzip2 -1 -k -v "${filename}" >&2
    fi

    # Upload to Google Cloud Storage
    echo "Uploading to GCS as ${bz2_filename}..." >&2
    rclone --progress copyto "${bz2_filename}" "${STORAGE_BUCKET}/${bz2_filename}" >&2 2>&1

    # Return the GCS URL
    echo "${STORAGE_URL}/${bz2_filename}"
}

# Function to create Digital Ocean image
create_do_image() {
    local image_type="$1"
    local gcs_url="$2"

    local image_name="FreeBSD-${TAG}-${ARCH}-${image_type}"
    local description="FreeBSD ${VERSION} ${image_type:u}"

    echo "Creating image (${image_type})..."

    doctl compute image create "${image_name}" \
        --region "${REGION}" \
        --image-distribution "${DISTRIBUTION}" \
        --tag-names "FreeBSD" \
        --image-description "${description}" \
        --image-url "${gcs_url}"
}

# Function to cleanup work directory
cleanup() {
    echo "Cleaning up temporary files..."
    if [[ -d "${WORK_DIR}" ]]; then
        rm -rf "${WORK_DIR}"
        echo "Cleanup complete."
    fi
}

# Main execution
main() {
    # Set trap to cleanup on exit
    trap cleanup EXIT

    # Process each image type
    for image_type in "${image_types[@]}"; do
        gcs_url=$(process_image "${image_type}")

        # Create image in Digital Ocean
        create_do_image "${image_type}" "${gcs_url}"
    done

    echo "All images processed and uploaded!"
}

# Run main function
main
