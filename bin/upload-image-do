#!/usr/bin/env zsh

set -o errexit -o nounset -o pipefail

# Parse command line arguments
zparseopts -D -E -F -- \
    r:=region_arg -region:=region_arg \
    k:=token_arg -token:=token_arg \
    i:=image_name_arg -image-name:=image_name_arg \
    d:=description_arg -description:=description_arg \
    n=dry_run_arg -dry-run=dry_run_arg \
    h=help_arg -help=help_arg || exit 1

# Show help if requested
if [[ -n "${help_arg}" ]]; then
    cat >&2 <<EOF
Usage: ${0:t} [options] URL

Download a FreeBSD image from a direct URL and upload to DigitalOcean.

Arguments:
    URL                 FreeBSD image URL (https://...) or local file path (/path/to/file)

Options:
    -r, --region REGION     DigitalOcean region (default: fra1)
    -i, --image-name NAME   DigitalOcean image name (required)
    -d, --description DESC  DigitalOcean image description (defaults to image name if not provided)
    -k, --token TOKEN       DigitalOcean API token (overrides DIGITALOCEAN_ACCESS_TOKEN)
    -n, --dry-run           Show operations without executing them
    -h, --help              Show this help message

Environment variables required:
    DIGITALOCEAN_ACCESS_TOKEN   DigitalOcean API token (or use -k/--token)
    STORAGE_BUCKET              Google Cloud Storage bucket (e.g., gs:bucket/path)
    STORAGE_URL                 Public URL for storage (e.g., https://storage.googleapis.com/bucket/path)

Examples:
    export DIGITALOCEAN_ACCESS_TOKEN=token
    export STORAGE_BUCKET=gs:mybucket/FreeBSD/images
    export STORAGE_URL=https://mybucket.storage.googleapis.com/FreeBSD/images

    # With image name and custom description
    ${0:t} -r nyc3 \\
        -i 'FreeBSD-15.0-BETA4-amd64-zfs' \\
        -d 'FreeBSD 15.0 Beta 4 ZFS' \\
        'https://download.freebsd.org/ftp/releases/VM-IMAGES/15.0-BETA4/amd64/Latest/FreeBSD-15.0-BETA4-amd64-BASIC-CLOUDINIT-zfs.qcow2.xz'

    # With image name only (description defaults to name)
    ${0:t} -r fra1 \\
        -i 'FreeBSD-14.3-RELEASE-amd64-zfs' \\
        'https://download.freebsd.org/ftp/releases/VM-IMAGES/14.3-RELEASE/amd64/Latest/FreeBSD-14.3-RELEASE-amd64-BASIC-CLOUDINIT-zfs.qcow2.xz'

    # Using local file
    ${0:t} -r fra1 \\
        -i 'FreeBSD-15.0-STABLE-amd64-zfs' \\
        '/path/to/FreeBSD-15.0-STABLE-amd64-BASIC-CLOUDINIT-zfs.qcow2.xz'
EOF
    exit 0
fi

# Get URL from positional argument
if [[ $# -lt 1 ]]; then
    echo "Error: URL is required" >&2
    exit 1
fi
URL="$1"

# Define variables
REGION="${region_arg[2]:-fra1}"
DRY_RUN="${dry_run_arg[1]:+true}"
WORK_DIR="/tmp/freebsd-image-upload"
DO_IMAGE_NAME="${image_name_arg[2]:-}"
DO_DESCRIPTION="${description_arg[2]:-}"

# Set DigitalOcean token from command line or environment
if [[ -n "${token_arg[2]:-}" ]]; then
    DIGITALOCEAN_ACCESS_TOKEN="${token_arg[2]}"
fi

# Check for required environment variables
if [[ -z "${DIGITALOCEAN_ACCESS_TOKEN:-}" ]]; then
    echo "Error: DIGITALOCEAN_ACCESS_TOKEN environment variable is not set (use -k/--token or set the environment variable)" >&2
    exit 1
fi

if [[ -z "${STORAGE_BUCKET:-}" ]]; then
    echo "Error: STORAGE_BUCKET environment variable is not set" >&2
    exit 1
fi

if [[ -z "${STORAGE_URL:-}" ]]; then
    echo "Error: STORAGE_URL environment variable is not set" >&2
    exit 1
fi

# Check if image name is provided (required)
if [[ -z "${DO_IMAGE_NAME}" ]]; then
    echo "Error: -i/--image-name is required" >&2
    exit 1
fi

# Extract filename from URL
REMOTE_FILENAME=$(basename "${URL}")
WORK_COMPRESSED="${WORK_DIR}/${REMOTE_FILENAME}"

# Determine decompressed and final filenames
if [[ "${REMOTE_FILENAME}" == *.xz ]]; then
    DECOMPRESSED="${WORK_COMPRESSED%.xz}"
elif [[ "${REMOTE_FILENAME}" == *.bz2 ]]; then
    DECOMPRESSED="${WORK_COMPRESSED%.bz2}"
else
    DECOMPRESSED="${WORK_COMPRESSED}"
fi

# Extract base filename (without compression)
BASENAME=$(basename "${DECOMPRESSED}")
FINAL_FILENAME="${BASENAME}.bz2"

echo "URL: ${URL}" >&2
echo "Remote filename: ${REMOTE_FILENAME}" >&2
echo "Work directory: ${WORK_DIR}" >&2
echo "Final upload name: ${FINAL_FILENAME}" >&2

# Create work directory
if [[ "${DRY_RUN}" == "true" ]]; then
    echo "[DRY-RUN] Would create work directory: ${WORK_DIR}" >&2
else
    mkdir -p "${WORK_DIR}"
    cd "${WORK_DIR}"
fi

# Download or copy image
# Detect if URL is a local file path or remote URL
if [[ "${URL}" =~ ^https?:// ]]; then
    # Remote URL - download with curl
    if [[ "${DRY_RUN}" == "true" ]]; then
        echo "[DRY-RUN] Would download: ${URL}" >&2
    else
        echo "Downloading image..." >&2
        if ! curl -L -f -o "${WORK_COMPRESSED}" "${URL}"; then
            rm -f "${WORK_COMPRESSED}"
            echo "Download failed, file removed" >&2
            exit 1
        fi
        echo "Download complete." >&2
    fi
else
    # Local file path - copy it
    if [[ "${DRY_RUN}" == "true" ]]; then
        echo "[DRY-RUN] Would copy local file: ${URL}" >&2
    else
        if [[ ! -f "${URL}" ]]; then
            echo "Error: Local file not found: ${URL}" >&2
            exit 1
        fi
        echo "Copying local file..." >&2
        if ! cp "${URL}" "${WORK_COMPRESSED}"; then
            rm -f "${WORK_COMPRESSED}"
            echo "Copy failed, file removed" >&2
            exit 1
        fi
        echo "Copy complete." >&2
    fi
fi

# Decompress if needed
if [[ "${REMOTE_FILENAME}" == *.xz || "${REMOTE_FILENAME}" == *.bz2 ]]; then
    if [[ "${DRY_RUN}" == "true" ]]; then
        echo "[DRY-RUN] Would decompress: ${WORK_COMPRESSED}" >&2
    else
        echo "Decompressing ${REMOTE_FILENAME}..." >&2
        if [[ "${REMOTE_FILENAME}" == *.xz ]]; then
            xz -d "${WORK_COMPRESSED}"
        else
            bzip2 -d "${WORK_COMPRESSED}"
        fi
        echo "Decompression complete." >&2
    fi
fi

# Recompress with bzip2 if needed (if original wasn't bzip2)
if [[ "${REMOTE_FILENAME}" != *.bz2 ]]; then
    if [[ "${DRY_RUN}" == "true" ]]; then
        echo "[DRY-RUN] Would compress with bzip2: ${BASENAME} -> ${FINAL_FILENAME}" >&2
    else
        echo "Compressing with bzip2..." >&2
        bzip2 -1 -v "${DECOMPRESSED}" >&2
        echo "Compression complete." >&2
    fi
fi

# Upload to Google Cloud Storage
UPLOAD_SOURCE="${WORK_DIR}/${FINAL_FILENAME}"
if [[ "${DRY_RUN}" == "true" ]]; then
    echo "[DRY-RUN] Would upload to GCS: ${FINAL_FILENAME} -> ${STORAGE_BUCKET}/${FINAL_FILENAME}" >&2
else
    echo "Uploading to GCS as ${FINAL_FILENAME}..." >&2
    rclone --progress copyto "${UPLOAD_SOURCE}" "${STORAGE_BUCKET}/${FINAL_FILENAME}" >&2 2>&1
    echo "Upload complete." >&2
fi

# Generate GCS URL
GCS_URL="${STORAGE_URL}/${FINAL_FILENAME}"
echo "GCS URL: ${GCS_URL}" >&2

# Create DigitalOcean image
IMAGE_NAME="${DO_IMAGE_NAME}"
DESCRIPTION="${DO_DESCRIPTION:-${DO_IMAGE_NAME}}"

echo "Image properties:" >&2
echo "  Name: ${IMAGE_NAME}" >&2
echo "  Description: ${DESCRIPTION}" >&2

if [[ "${DRY_RUN}" == "true" ]]; then
    echo "[DRY-RUN] Would create DigitalOcean image:"
    echo "  Name: ${IMAGE_NAME}"
    echo "  Region: ${REGION}"
    echo "  Description: ${DESCRIPTION}"
    echo "  URL: ${GCS_URL}"
else
    echo "Creating DigitalOcean image..." >&2
    doctl compute image create "${IMAGE_NAME}" \
        --region "${REGION}" \
        --tag-names "FreeBSD" \
        --image-description "${DESCRIPTION}" \
        --image-url "${GCS_URL}" >&2
    echo "Image creation initiated." >&2
fi

# Cleanup
if [[ "${DRY_RUN}" == "true" ]]; then
    echo "[DRY-RUN] Would clean up temporary files in: ${WORK_DIR}"
else
    echo "Cleaning up temporary files..." >&2
    rm -rf "${WORK_DIR}"
    echo "Done!" >&2
fi
